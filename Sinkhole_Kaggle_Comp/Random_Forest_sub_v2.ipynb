{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#train = pd.read_csv('/kaggle/input/train.csv')\n",
    "#test = pd.read_csv('/kaggle/input/test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the training data into train and validation data using numpy sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4105     0\n",
      "12650    0\n",
      "7039     0\n",
      "3310     0\n",
      "16360    1\n",
      "11838    0\n",
      "15301    0\n",
      "2697     0\n",
      "217      1\n",
      "1493     0\n",
      "5012     0\n",
      "13202    0\n",
      "13589    0\n",
      "928      0\n",
      "11491    1\n",
      "6876     0\n",
      "14351    0\n",
      "7047     1\n",
      "14935    0\n",
      "14403    0\n",
      "4546     0\n",
      "11331    0\n",
      "10753    0\n",
      "11957    0\n",
      "1450     0\n",
      "3282     0\n",
      "322      1\n",
      "12796    0\n",
      "17194    0\n",
      "14133    0\n",
      "        ..\n",
      "13750    0\n",
      "16913    0\n",
      "4062     1\n",
      "16258    0\n",
      "9750     0\n",
      "12270    0\n",
      "7278     0\n",
      "1415     0\n",
      "17454    1\n",
      "6624     0\n",
      "6775     0\n",
      "8688     0\n",
      "2163     0\n",
      "11434    0\n",
      "12914    0\n",
      "11712    0\n",
      "12939    0\n",
      "7889     0\n",
      "12314    0\n",
      "9855     0\n",
      "17038    0\n",
      "7614     0\n",
      "1594     0\n",
      "6286     0\n",
      "14832    0\n",
      "14919    1\n",
      "8246     0\n",
      "4772     0\n",
      "7803     1\n",
      "9616     0\n",
      "Name: IsSinkhole, Length: 6041, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split Training data and validation data\n",
    "#train_train = train.sample(frac=0.8,random_state=43)\n",
    "#train_valid = train.drop(train_train.index).reset_index(drop=True)\n",
    "\n",
    "train_train, train_valid, y_train, y_valid = train_test_split(train.drop(columns=['ID','IsSinkhole']), train.IsSinkhole, test_size=0.33, random_state=42)\n",
    "\n",
    "print(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data and Choose Model\n",
    "\n",
    "I use the sklearn preprocessing function to normalize the data and obtain a transformation matrix\n",
    "\n",
    "I chose to use the sklearn RandomForestClassifier() function as my model\n",
    "\n",
    "I use the sklearn f1_score function to validate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "0.7608850820842256\n"
     ]
    }
   ],
   "source": [
    "# Normalize the train_train data and create the transformation\n",
    "train_normal = preprocessing.scale(train_train)\n",
    "train_scaler = preprocessing.StandardScaler().fit(train_train)\n",
    "\n",
    "# Train the model\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=10)\n",
    "\n",
    "# Fit the model to the data\n",
    "clf.fit(X=train_train,y=y_train)\n",
    "\n",
    "# Validate the current model using train_valid\n",
    "#predict_train = clf.predict(train_scaler.transform(train_valid),)\n",
    "predict_train = clf.predict(train_valid,)\n",
    "\n",
    "print(predict_train)\n",
    "f1 = f1_score(y_valid,predict_train)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the trained model on the test data\n",
    "\n",
    "I save the results over the test data to .csv file in the format prescribed by the kaggle Comp\n",
    "\n",
    "--> Note that we need to scale the test data or the trained weights will not work properly\n",
    "        I use the sklearn preprocessing.StandScaler().fit() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = clf.predict(train_scaler.transform(test.drop(columns=['ID'])),)\n",
    "#test['IsSinkhole'] = predictions\n",
    "#test.to_csv('Lippay_random_forest_classifier.csv',index_label='ID',columns=['IsSinkhole'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
